{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QeQLP_jNVz7j",
        "outputId": "7564cf87-9c1d-4ef2-bfd2-65989f346136"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-0.3.25-py3-none-any.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: langsmith in /usr/local/lib/python3.11/dist-packages (0.3.22)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.22)\n",
            "Collecting langchain_groq\n",
            "  Downloading langchain_groq-0.3.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.21-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.49)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.0.24-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-prebuilt<0.2,>=0.1.1 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.1.8-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.61-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting xxhash<4.0.0,>=3.5.0 (from langgraph)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith) (3.10.16)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langsmith) (24.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.11/dist-packages (from langsmith) (2.11.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith) (0.23.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Collecting groq<1,>=0.4.1 (from langchain_groq)\n",
            "  Downloading groq-0.22.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting langchain-core<0.4,>=0.1 (from langgraph)\n",
            "  Downloading langchain_core-0.3.51-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.3.23-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
            "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.3.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (4.13.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.14.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (1.33)\n",
            "Collecting ormsgpack<2.0.0,>=1.8.0 (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph)\n",
            "  Downloading ormsgpack-1.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langsmith) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langsmith) (2.33.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langsmith) (0.4.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith) (2.3.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.1->langgraph) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langgraph-0.3.25-py3-none-any.whl (142 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m142.4/142.4 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_groq-0.3.2-py3-none-any.whl (15 kB)\n",
            "Downloading langchain_community-0.3.21-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.3.23-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading groq-0.22.0-py3-none-any.whl (126 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m126.7/126.7 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain_core-0.3.51-py3-none-any.whl (423 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m423.3/423.3 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
            "Downloading langgraph_checkpoint-2.0.24-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.1.8-py3-none-any.whl (25 kB)\n",
            "Downloading langgraph_sdk-0.1.61-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
            "Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (223 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: xxhash, python-dotenv, ormsgpack, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, langgraph-sdk, groq, dataclasses-json, langchain-core, langgraph-checkpoint, langchain-text-splitters, langchain_groq, langgraph-prebuilt, langchain, langgraph, langchain_community\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.49\n",
            "    Uninstalling langchain-core-0.3.49:\n",
            "      Successfully uninstalled langchain-core-0.3.49\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.7\n",
            "    Uninstalling langchain-text-splitters-0.3.7:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.7\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.22\n",
            "    Uninstalling langchain-0.3.22:\n",
            "      Successfully uninstalled langchain-0.3.22\n",
            "Successfully installed dataclasses-json-0.6.7 groq-0.22.0 httpx-sse-0.4.0 langchain-0.3.23 langchain-core-0.3.51 langchain-text-splitters-0.3.8 langchain_community-0.3.21 langchain_groq-0.3.2 langgraph-0.3.25 langgraph-checkpoint-2.0.24 langgraph-prebuilt-0.1.8 langgraph-sdk-0.1.61 marshmallow-3.26.1 mypy-extensions-1.0.0 ormsgpack-1.9.1 pydantic-settings-2.8.1 python-dotenv-1.1.0 typing-inspect-0.9.0 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langgraph langsmith langchain langchain_groq langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "from google.colab import userdata\n",
        "groq_api_key = userdata.get('groq_api_key')"
      ],
      "metadata": {
        "id": "A9Qhe32kV21r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, List, TypedDict, Annotated, Sequence, Any\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "import operator\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.runnables import RunnableConfig\n",
        "import json\n",
        "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
        "import re\n",
        "\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from typing_extensions import Literal\n",
        "from langchain_core.prompts import ChatPromptTemplate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZKwhRMMvV23_",
        "outputId": "9ad0f846-8b39-434e-f8ae-b8fdba6be62f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py:3553: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
            "\n",
            "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
            "with: `from pydantic import BaseModel`\n",
            "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
            "\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphState(TypedDict):  # Class GraphState\n",
        "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
        "    current_agent: str\n",
        "    current_llm_model: str\n",
        "    context_summary: str\n",
        "\n",
        "state = StateGraph(GraphState)"
      ],
      "metadata": {
        "id": "Nx0uzJCFeIJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_generator = ChatGroq(groq_api_key=groq_api_key, model=\"Gemma2-9b-It\")\n",
        "system = \"\"\"You are a prompt generator for text to image model. Your task is to generate 50 diffrent prompts for text to image model to generate diverse images given to you\n",
        "the scenarios. example if I give you scenario as 'people in distress in the context to disaster' you give me different prompts for image generator model to\n",
        "generate a complete dataset of images of people in distress covering diverse scenarios. \"\"\"\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"{question}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "prompt_generator_agent = prompt | prompt_generator\n",
        "\n",
        "def prompt_generator_handler(state: GraphState):\n",
        "    \"\"\" The marketing RAG powered Agent to resolve user queries\"\"\"\n",
        "\n",
        "    question = state[\"messages\"][-1].content\n",
        "\n",
        "    inbuilt_query = f\"\"\" You are a prompt generator for a text-to-image model. Given the user scenario and access to the full conversation history,\n",
        "your task is to generate 50 diverse and creative image generation prompts based on the scenario provided by the user.\n",
        "Make sure the prompts cover a wide range of sub-scenarios, perspectives, environments, and subjects to create a comprehensive dataset of images.\n",
        "what i need as the output exactly is: return the python list of 50 prompt strings.\n",
        "\n",
        "User scenario:\n",
        "{question}\n",
        "\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    response = prompt_generator_agent.invoke(inbuilt_query)\n",
        "\n",
        "    # Add the question-response pair to conversation_history\n",
        "    conversation_id = len(state[\"conversation_history\"]) + 1\n",
        "    state[\"conversation_history\"][conversation_id] = {\n",
        "        \"question\": question,\n",
        "        \"response\": response\n",
        "    }\n",
        "\n",
        "    state[\"llm_model\"] = \"Gemma2-9b-It\"\n",
        "\n",
        "    # Also add the AI response to the messages list\n",
        "    state[\"messages\"].append(AIMessage(content=response.content))\n",
        "\n",
        "    # Update the current_agent within the state dictionary\n",
        "    state['current_agent'] = \"prompt_generator_agent\"  # Or the appropriate agent name\n",
        "\n",
        "    # Return the updated state\n",
        "    return state\n"
      ],
      "metadata": {
        "id": "CdiqxrarV26F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_generator = ChatGroq(groq_api_key=groq_api_key, model=\"Gemma2-9b-It\")\n",
        "system = \"\"\"You are a prompt generator for text to image model. Your task is to generate 50 diffrent prompts for text to image model to generate diverse images given to you\n",
        "the scenarios. example if I give you scenario as 'people in distress in the context to disaster' you give me different prompts for image generator model to\n",
        "generate a complete dataset of images of people in distress covering diverse scenarios. \"\"\"\n",
        "chat_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"{question}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "chat_agent = chat_prompt | chat_generator\n",
        "\n",
        "def chat_handler(state: GraphState):\n",
        "    \"\"\" The marketing RAG powered Agent to resolve user queries\"\"\"\n",
        "\n",
        "    question = state[\"messages\"][-1].content\n",
        "\n",
        "    inbuilt_query = f\"\"\" You are a prompt generator for a text-to-image model. Given the user scenario and access to the full conversation history,\n",
        "your task is to generate 50 diverse and creative image generation prompts based on the scenario provided by the user.\n",
        "Make sure the prompts cover a wide range of sub-scenarios, perspectives, environments, and subjects to create a comprehensive dataset of images.\n",
        "\n",
        "User scenario:\n",
        "{question}\n",
        "    \"\"\"\n",
        "    response = prompt_generator_agent.invoke(inbuilt_query)\n",
        "\n",
        "    # Add the question-response pair to conversation_history\n",
        "    conversation_id = len(state[\"conversation_history\"]) + 1\n",
        "    state[\"conversation_history\"][conversation_id] = {\n",
        "        \"question\": question,\n",
        "        \"response\": response\n",
        "    }\n",
        "\n",
        "    state[\"llm_model\"] = \"Gemma2-9b-It\"\n",
        "\n",
        "    # Also add the AI response to the messages list\n",
        "    state[\"messages\"].append(AIMessage(content=response.content))\n",
        "\n",
        "    # Update the current_agent within the state dictionary\n",
        "    state['current_agent'] = \"chat_agent\"  # Or the appropriate agent name\n",
        "\n",
        "    # Return the updated state\n",
        "    return state\n"
      ],
      "metadata": {
        "id": "Silkk4JBG0bI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import requests\n",
        "import os\n",
        "from time import sleep\n",
        "\n",
        "# âœ… Fetch your API key from environment variable in Colab\n",
        "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
        "\n",
        "# âœ… Folder to save generated images\n",
        "output_dir = \"/content/generated_images\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# âœ… Your list of prompts (replace with your actual list)\n",
        "prompt_list = [\n",
        "    \"people in distress during an earthquake in an urban area\",\n",
        "    \"flood rescue team helping an elderly person\",\n",
        "    \"wildfire approaching a suburban neighborhood with smoke in the air\",\n",
        "    # ... (up to 50 prompts)\n",
        "]\n",
        "\n",
        "# âœ… Generate and save images\n",
        "for idx, prompt in enumerate(prompt_list):\n",
        "    try:\n",
        "        print(f\"[{idx+1}/50] Generating image for prompt: {prompt}\")\n",
        "\n",
        "        response = openai.Image.create(\n",
        "            model=\"dall-e-3\",\n",
        "            prompt=prompt,\n",
        "            size=\"256x256\",\n",
        "            n=1,\n",
        "            response_format=\"url\"\n",
        "        )\n",
        "\n",
        "        image_url = response['data'][0]['url']\n",
        "\n",
        "        # Download the image\n",
        "        image_data = requests.get(image_url).content\n",
        "        file_path = os.path.join(output_dir, f\"image_{idx+1:02}.png\")\n",
        "\n",
        "        with open(file_path, 'wb') as f:\n",
        "            f.write(image_data)\n",
        "\n",
        "        print(f\"âœ… Image saved: {file_path}\")\n",
        "\n",
        "        sleep(1)  # Optional: to prevent rate limits\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error on prompt {idx+1}: {e}\")\n"
      ],
      "metadata": {
        "id": "DJsSRofUG0Mh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Initialize the state\n",
        "    initial_state = {\n",
        "        \"messages\": [],\n",
        "        \"current_agent\": \"prompt_generator_agent\",  # Set initial agent\n",
        "        \"current_llm_model\": \"deepseek-r1-distill-qwen-32b\",\n",
        "        \"context_summary\": \"\",\n",
        "        \"conversation_history\": {} # Initialize conversation history\n",
        "    }\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"Enter a scenario (or type 'exit' to quit): \")\n",
        "        if user_input.lower() == 'exit':\n",
        "            break\n",
        "\n",
        "        # Create a HumanMessage from the input\n",
        "        initial_state[\"messages\"].append(HumanMessage(content=user_input))\n",
        "\n",
        "        # Invoke the prompt_generator_handler\n",
        "        updated_state = prompt_generator_handler(initial_state)\n",
        "\n",
        "        # Print or process the updated state's AI response\n",
        "        print(updated_state[\"messages\"][-1].content)\n",
        "\n",
        "        # Update the initial state with the new state for the next iteration\n",
        "        initial_state = updated_state\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RS302m6eVGU",
        "outputId": "da2f1075-764b-4886-82ad-16faaa1140de"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter a scenario (or type 'exit' to quit): dataset of supercars\n",
            "```python\n",
            "[\n",
            "    \"A sleek red Ferrari F40 roaring down a rainy city street\",\n",
            "    \"A Lamborghini Aventador SVJ parked in front of a luxurious mansion\",\n",
            "    \"A group of supercars, including a McLaren P1, Bugatti Veyron, and Koenigsegg Regera, lined up on a racetrack\",\n",
            "    \"A Porsche 918 Spyder accelerating through a tunnel with blurred lights\",\n",
            "    \"An Aston Martin Valkyrie parked in a dimly lit garage, reflecting the light from a single spotlight\",\n",
            "    \"A classic Ferrari 250 GTO driving through a picturesque Tuscan countryside\",\n",
            "    \"A Bugatti Chiron Pur Sport speeding through a desert landscape\",\n",
            "    \"A Pagani Huayra Roadster BC driving along a winding coastal road\",\n",
            "    \"A Rimac Nevera driving through a futuristic cityscape\",\n",
            "    \"A group of supercars showcasing their unique designs at a car show\",\n",
            "    \"A close-up shot of the intricate details of a Lamborghini Aventador's engine\",\n",
            "    \"A panoramic view of a supercar collection parked on a hilltop overlooking a valley\",\n",
            "    \"A supercar drifting through a corner on a racetrack, smoke billowing from its tires\",\n",
            "    \"A supercar being meticulously polished in a high-end car dealership\",\n",
            "    \"A child gazing in awe at a supercar parked in front of a museum\",\n",
            "    \"A supercar driver wearing a racing helmet and suit, preparing to race\",\n",
            "    \"A supercar speeding down a highway, leaving a trail of exhaust fumes\",\n",
            "    \"A drone shot capturing the sleek lines of a supercar driving through a forest\",\n",
            "    \"A supercar parked in front of a skyscraper, reflecting the city lights\",\n",
            "    \"A low-angle shot of a supercar accelerating off the line\",\n",
            "    \"A supercar parked in a garage next to vintage motorcycles\",\n",
            "    \"A supercar being transported on a trailer\",\n",
            "    \"A supercar interior shot showcasing the luxurious leather seats and advanced technology\",\n",
            "    \"A sunset shot of a supercar parked on a beach\",\n",
            "    \"A supercar driving through a snow-covered mountain pass\",\n",
            "    \"A supercar parked in front of a historical landmark\",\n",
            "    \"A close-up shot of the supercar's headlights illuminating the road\",\n",
            "    \"A supercar driving through a dense fog\",\n",
            "    \"A supercar parked in a private hangar next to a private jet\",\n",
            "    \"A supercar race taking place on a dirt track\",\n",
            "    \"A supercar being driven through a flooded street\",\n",
            "    \"A supercar parked in a field of wildflowers\",\n",
            "    \"A supercar driving through a tropical rainforest\",\n",
            "    \"A supercar being driven through a tunnel with colorful neon lights\",\n",
            "    \"A supercar parked in front of a futuristic building\",\n",
            "    \"A supercar driving through a city at night, with reflections in the puddles\",\n",
            "    \"A supercar parked in a deserted parking lot, lit by streetlights\",\n",
            "    \"A supercar driving through a field of tall grass\",\n",
            "    \"A supercar parked in a luxurious villa garden\",\n",
            "    \"A supercar being lowered onto a platform for display\",\n",
            "    \"A supercar driving through a cityscape with flying cars\",\n",
            "    \"A supercar interior shot with the driver wearing virtual reality goggles\",\n",
            "    \"A supercar being chased by police cars\",\n",
            "    \"A supercar parked on a helipad\"\n",
            "]\n",
            "```\n",
            "\n",
            "\n",
            "\n",
            "Enter a scenario (or type 'exit' to quit): exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import requests\n",
        "import os\n",
        "import ast\n",
        "from time import sleep\n",
        "\n",
        "# Set OpenAI API key from Colab's env\n",
        "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
        "\n",
        "# Directory to save images\n",
        "output_dir = \"/content/generated_images\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# === ğŸ” STEP 1: Invoke your prompt generator agent ===\n",
        "scenario = \"realistic cinematic images of supercars in different scenarios\"\n",
        "agent_output = moderator_agent.invoke(scenario)\n",
        "\n",
        "# === ğŸ§  STEP 2: Parse output string to Python list ===\n",
        "# agent_output.content should be a string like: '[\"prompt1\", \"prompt2\", ...]'\n",
        "try:\n",
        "    prompt_list = ast.literal_eval(agent_output.content)\n",
        "    if not isinstance(prompt_list, list):\n",
        "        raise ValueError(\"Parsed output is not a list.\")\n",
        "except Exception as e:\n",
        "    raise ValueError(f\"Failed to parse prompts from agent: {e}\")\n",
        "\n",
        "print(f\"âœ… Got {len(prompt_list)} prompts from agent!\")\n",
        "\n",
        "# === ğŸ¨ STEP 3: Generate and save images ===\n",
        "for idx, prompt in enumerate(prompt_list):\n",
        "    try:\n",
        "        print(f\"[{idx+1}/{len(prompt_list)}] Generating image for prompt: {prompt}\")\n",
        "\n",
        "        response = openai.Image.create(\n",
        "            model=\"dall-e-3\",\n",
        "            prompt=prompt,\n",
        "            size=\"1024x1024\",\n",
        "            n=1,\n",
        "            response_format=\"url\"\n",
        "        )\n",
        "\n",
        "        image_url = response[\"data\"][0][\"url\"]\n",
        "        image_data = requests.get(image_url).content\n",
        "        file_path = os.path.join(output_dir, f\"image_{idx+1:02}.png\")\n",
        "\n",
        "        with open(file_path, 'wb') as f:\n",
        "            f.write(image_data)\n",
        "\n",
        "        print(f\"âœ… Saved: {file_path}\")\n",
        "        sleep(1)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error with prompt {idx+1}: {e}\")\n"
      ],
      "metadata": {
        "id": "pVNemTlLV28W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NcZdo9WeV2-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IoS_BAAJV3B5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}