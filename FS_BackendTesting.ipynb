{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QeQLP_jNVz7j",
        "outputId": "970b779a-bcc3-4475-fa4f-2530ae382663"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-0.3.27-py3-none-any.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: langsmith in /usr/local/lib/python3.11/dist-packages (0.3.23)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.22)\n",
            "Collecting langchain_groq\n",
            "  Downloading langchain_groq-0.3.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.21-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.50)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.0.24-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-prebuilt<0.2,>=0.1.1 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.1.8-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.61-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting xxhash<4.0.0,>=3.5.0 (from langgraph)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith) (3.10.16)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langsmith) (24.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.11/dist-packages (from langsmith) (2.11.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith) (0.23.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Collecting groq<1,>=0.4.1 (from langchain_groq)\n",
            "  Downloading groq-0.22.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting langchain-core<0.4,>=0.1 (from langgraph)\n",
            "  Downloading langchain_core-0.3.51-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.3.23-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
            "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (4.13.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.14.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (1.33)\n",
            "Collecting ormsgpack<2.0.0,>=1.8.0 (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph)\n",
            "  Downloading ormsgpack-1.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langsmith) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langsmith) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langsmith) (0.4.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith) (2.3.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.1->langgraph) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langgraph-0.3.27-py3-none-any.whl (142 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m143.0/143.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_groq-0.3.2-py3-none-any.whl (15 kB)\n",
            "Downloading langchain_community-0.3.21-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.3.23-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading groq-0.22.0-py3-none-any.whl (126 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m126.7/126.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain_core-0.3.51-py3-none-any.whl (423 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m423.3/423.3 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
            "Downloading langgraph_checkpoint-2.0.24-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.1.8-py3-none-any.whl (25 kB)\n",
            "Downloading langgraph_sdk-0.1.61-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
            "Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (223 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: xxhash, python-dotenv, ormsgpack, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, langgraph-sdk, groq, dataclasses-json, langchain-core, langgraph-checkpoint, langchain-text-splitters, langchain_groq, langgraph-prebuilt, langchain, langgraph, langchain_community\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.50\n",
            "    Uninstalling langchain-core-0.3.50:\n",
            "      Successfully uninstalled langchain-core-0.3.50\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.7\n",
            "    Uninstalling langchain-text-splitters-0.3.7:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.7\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.22\n",
            "    Uninstalling langchain-0.3.22:\n",
            "      Successfully uninstalled langchain-0.3.22\n",
            "Successfully installed dataclasses-json-0.6.7 groq-0.22.0 httpx-sse-0.4.0 langchain-0.3.23 langchain-core-0.3.51 langchain-text-splitters-0.3.8 langchain_community-0.3.21 langchain_groq-0.3.2 langgraph-0.3.27 langgraph-checkpoint-2.0.24 langgraph-prebuilt-0.1.8 langgraph-sdk-0.1.61 marshmallow-3.26.1 mypy-extensions-1.0.0 ormsgpack-1.9.1 pydantic-settings-2.8.1 python-dotenv-1.1.0 typing-inspect-0.9.0 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langgraph langsmith langchain langchain_groq langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "from google.colab import userdata\n",
        "groq_api_key = userdata.get('groq_api_key')"
      ],
      "metadata": {
        "id": "A9Qhe32kV21r"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, List, TypedDict, Annotated, Sequence, Any\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "import operator\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.runnables import RunnableConfig\n",
        "import json\n",
        "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
        "import re\n",
        "\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from typing_extensions import Literal\n",
        "from langchain_core.prompts import ChatPromptTemplate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZKwhRMMvV23_",
        "outputId": "df09a7d2-8670-4b2f-c416-9fad38c74347"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py:3553: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
            "\n",
            "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
            "with: `from pydantic import BaseModel`\n",
            "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
            "\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphState(TypedDict):  # Class GraphState\n",
        "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
        "    current_agent: str\n",
        "    current_llm_model: str\n",
        "    context_summary: str\n",
        "\n",
        "state = StateGraph(GraphState)"
      ],
      "metadata": {
        "id": "Nx0uzJCFeIJy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_generator = ChatGroq(groq_api_key=groq_api_key, model=\"Gemma2-9b-It\")\n",
        "system = \"\"\"You are a prompt generator for text to image model. Your task is to generate 50 diffrent prompts for text to image model to generate diverse images given to you\n",
        "the scenarios. example if I give you scenario as 'people in distress in the context to disaster' you give me different prompts for image generator model to\n",
        "generate a complete dataset of images of people in distress covering diverse scenarios. \"\"\"\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"{question}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "prompt_generator_agent = prompt | prompt_generator\n",
        "\n",
        "def prompt_generator_handler(state: GraphState):\n",
        "    \"\"\" The marketing RAG powered Agent to resolve user queries\"\"\"\n",
        "\n",
        "    question = state[\"messages\"][-1].content\n",
        "\n",
        "    inbuilt_query = f\"\"\" You are a prompt generator for a text-to-image model. Given the user scenario and access to the full conversation history,\n",
        "your task is to generate 50 diverse and creative image generation prompts based on the scenario provided by the user.\n",
        "Make sure the prompts cover a wide range of sub-scenarios, perspectives, environments, and subjects to create a comprehensive dataset of images.\n",
        "what i need as the output exactly is: return the python list of 50 prompt strings. agent_output.content should be a string like: '[\"prompt1\", \"prompt2\", ...]'\n",
        "\n",
        "User scenario:\n",
        "{question}\n",
        "\n",
        "    \"\"\"\n",
        "    response = prompt_generator_agent.invoke(inbuilt_query)\n",
        "\n",
        "    # Add the question-response pair to conversation_history\n",
        "    conversation_id = len(state[\"conversation_history\"]) + 1\n",
        "    state[\"conversation_history\"][conversation_id] = {\n",
        "        \"question\": question,\n",
        "        \"response\": response\n",
        "    }\n",
        "\n",
        "    state[\"llm_model\"] = \"Gemma2-9b-It\"\n",
        "\n",
        "    # Also add the AI response to the messages list\n",
        "    state[\"messages\"].append(AIMessage(content=response.content))\n",
        "\n",
        "    # Update the current_agent within the state dictionary\n",
        "    state['current_agent'] = \"prompt_generator_agent\"  # Or the appropriate agent name\n",
        "\n",
        "    # Return the updated state\n",
        "    return state\n"
      ],
      "metadata": {
        "id": "CdiqxrarV26F"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_generator = ChatGroq(groq_api_key=groq_api_key, model=\"Gemma2-9b-It\")\n",
        "system = \"\"\"You are a prompt generator for text to image model. Your task is to generate 50 diffrent prompts for text to image model to generate diverse images given to you\n",
        "the scenarios. example if I give you scenario as 'people in distress in the context to disaster' you give me different prompts for image generator model to\n",
        "generate a complete dataset of images of people in distress covering diverse scenarios. \"\"\"\n",
        "chat_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"{question}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "chat_agent = chat_prompt | chat_generator\n",
        "\n",
        "def chat_handler(state: GraphState):\n",
        "    \"\"\" The marketing RAG powered Agent to resolve user queries\"\"\"\n",
        "\n",
        "    question = state[\"messages\"][-1].content\n",
        "\n",
        "    inbuilt_query = f\"\"\" You are a prompt generator for a text-to-image model. Given the user scenario and access to the full conversation history,\n",
        "your task is to generate 50 diverse and creative image generation prompts based on the scenario provided by the user.\n",
        "Make sure the prompts cover a wide range of sub-scenarios, perspectives, environments, and subjects to create a comprehensive dataset of images.\n",
        "\n",
        "User scenario:\n",
        "{question}\n",
        "    \"\"\"\n",
        "    response = prompt_generator_agent.invoke(inbuilt_query)\n",
        "\n",
        "    # Add the question-response pair to conversation_history\n",
        "    conversation_id = len(state[\"conversation_history\"]) + 1\n",
        "    state[\"conversation_history\"][conversation_id] = {\n",
        "        \"question\": question,\n",
        "        \"response\": response\n",
        "    }\n",
        "\n",
        "    state[\"llm_model\"] = \"Gemma2-9b-It\"\n",
        "\n",
        "    # Also add the AI response to the messages list\n",
        "    state[\"messages\"].append(AIMessage(content=response.content))\n",
        "\n",
        "    # Update the current_agent within the state dictionary\n",
        "    state['current_agent'] = \"chat_agent\"  # Or the appropriate agent name\n",
        "\n",
        "    # Return the updated state\n",
        "    return state\n"
      ],
      "metadata": {
        "id": "Silkk4JBG0bI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Initialize the state\n",
        "    initial_state = {\n",
        "        \"messages\": [],\n",
        "        \"current_agent\": \"prompt_generator_agent\",  # Set initial agent\n",
        "        \"current_llm_model\": \"deepseek-r1-distill-qwen-32b\",\n",
        "        \"context_summary\": \"\",\n",
        "        \"conversation_history\": {} # Initialize conversation history\n",
        "    }\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"Enter a scenario (or type 'exit' to quit): \")\n",
        "        if user_input.lower() == 'exit':\n",
        "            break\n",
        "\n",
        "        # Create a HumanMessage from the input\n",
        "        initial_state[\"messages\"].append(HumanMessage(content=user_input))\n",
        "\n",
        "        # Invoke the prompt_generator_handler\n",
        "        updated_state = prompt_generator_handler(initial_state)\n",
        "\n",
        "        # Print or process the updated state's AI response\n",
        "        print(updated_state[\"messages\"][-1].content)\n",
        "\n",
        "        # Update the initial state with the new state for the next iteration\n",
        "        initial_state = updated_state\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RS302m6eVGU",
        "outputId": "8d0da30f-c6b9-419a-acfe-34de56cea3f2",
        "collapsed": true
      },
      "execution_count": 11,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter a scenario (or type 'exit' to quit): Birds\n",
            "```python\n",
            "agent_output = [\n",
            "    \"A majestic bald eagle soaring above snow-capped mountains at sunset\",\n",
            "    \"A hummingbird hovering in mid-air, sipping nectar from a vibrant flower\",\n",
            "    \"A flock of colorful parrots squawking in a lush rainforest canopy\",\n",
            "    \"A lone penguin waddling across a frozen Antarctic landscape\",\n",
            "    \"A pair of lovebirds perched on a tree branch, cuddling each other\",\n",
            "    \"A tiny wren singing a beautiful melody in a dew-kissed garden\",\n",
            "    \"A peacock spreading its iridescent tail feathers in a display of grandeur\",\n",
            "    \"A group of owls perched on branches, their glowing eyes observing the night\",\n",
            "    \"A majestic owl with its wings spread wide, silhouetted against a full moon\",\n",
            "    \"A cardinal perched on a snow-covered branch, its bright red plumage contrasting with the white\",\n",
            "    \"A flock of starlings flying in a mesmerizing V-formation across a clear blue sky\",\n",
            "    \"A blue jay perched on a fence post, its blue and white feathers shimmering in the sunlight\",\n",
            "    \"A woodpecker hammering away at a tree trunk, its red crest bobbing\",\n",
            "    \"A hawk soaring high above the ground, its keen eyes searching for prey\",\n",
            "    \"A family of ducks swimming in a calm pond, their ducklings trailing behind\",\n",
            "    \"A swan gliding gracefully across a lake, its white feathers reflecting the sunlight\",\n",
            "    \"A goose honking loudly, flying in formation with its flock\",\n",
            "    \"A vulture circling high above a vast desert landscape\",\n",
            "    \"A robin building a nest in a tree branch\",\n",
            "    \"A sparrow hopping on the ground, searching for seeds\",\n",
            "    \"A hummingbird feeding on a flower, its wings beating rapidly\",\n",
            "    \"A parrot mimicking the sounds of a human voice\",\n",
            "    \"A crow perched on a rooftop, its dark feathers blending with the shadows\",\n",
            "    \"A pigeon landing on a statue in a city park\",\n",
            "    \"A flock of geese flying south for the winter\",\n",
            "    \"A snowy owl perched on a snowdrift, its white plumage camouflaged against the snowy backdrop\",\n",
            "    \"A bluebird singing in a tree\",\n",
            "    \"A butterfly perched on a bird's beak\",\n",
            "    \"A bird's nest filled with eggs\",\n",
            "    \"A bird flying through a thunderstorm\",\n",
            "    \"A bird's eye view of a forest\",\n",
            "    \"A bird's feather close-up\",\n",
            "    \"A bird skeleton\",\n",
            "    \"An abstract representation of a bird in flight\",\n",
            "    \"A bird made entirely of flowers\",\n",
            "    \"A surreal landscape with giant birds flying overhead\",\n",
            "    \"A dystopian city where birds are extinct\",\n",
            "    \"A dreamlike scene with birds transforming into other creatures\",\n",
            "    \"A bird symbolizing freedom and hope\",\n",
            "    \"A bird representing loneliness and isolation\",\n",
            "    \"A bird representing wisdom and knowledge\",\n",
            "    \"A bird representing beauty and grace\",\n",
            "    \"A bird representing danger and fear\",\n",
            "    \"A bird representing the cycle of life and death\",\n",
            "    \"A bird representing the connection between humans and nature\"\n",
            "]\n",
            "\n",
            "```\n",
            "\n",
            "Enter a scenario (or type 'exit' to quit): exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import requests\n",
        "import os\n",
        "import ast\n",
        "from time import sleep\n",
        "\n",
        "# Set OpenAI API key from Colab's env\n",
        "# openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
        "\n",
        "# Directory to save images\n",
        "output_dir = \"/content/generated_images\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "initial_state = {\n",
        "        \"messages\": [],\n",
        "        \"current_agent\": \"prompt_generator_agent\",  # Set initial agent\n",
        "        \"current_llm_model\": \"deepseek-r1-distill-qwen-32b\",\n",
        "        \"context_summary\": \"\",\n",
        "        \"conversation_history\": {} # Initialize conversation history\n",
        "    }\n",
        "\n",
        "# === ðŸ” STEP 1: Invoke your prompt generator agent ===\n",
        "scenario = input(\"Enter a scenario (or type 'exit' to quit): \")\n",
        "# agent_output = prompt_generator_agent.invoke(scenario)\n",
        "\n",
        "initial_state[\"messages\"].append(HumanMessage(content=scenario))\n",
        "\n",
        "# Invoke the prompt_generator_handler\n",
        "updated_state = prompt_generator_handler(initial_state)\n",
        "\n",
        "# Print or process the updated state's AI response\n",
        "agent_output = updated_state[\"messages\"][-1].content\n",
        "print(updated_state[\"messages\"][-1].content)\n",
        "\n",
        "# Update the initial state with the new state for the next iteration\n",
        "initial_state = updated_state\n",
        "\n",
        "\n",
        "# === ðŸ§  STEP 2: Parse output string to Python list ===\n",
        "# agent_output.content should be a string like: '[\"prompt1\", \"prompt2\", ...]'\n",
        "\n",
        "\n",
        "try:\n",
        "    # Attempt to parse as JSON first\n",
        "    prompt_list = json.loads(agent_output)\n",
        "\n",
        "    # If JSON parsing fails, fallback to ast.literal_eval\n",
        "except json.JSONDecodeError:\n",
        "    try:\n",
        "        prompt_list = ast.literal_eval(agent_output)\n",
        "    except (SyntaxError, ValueError) as e:\n",
        "        # If both JSON and literal_eval fail, extract prompts using regex\n",
        "        prompt_pattern = r'\"(.*?)\"'  # Matches text within double quotes\n",
        "        prompt_list = re.findall(prompt_pattern, agent_output)\n",
        "        if not prompt_list:\n",
        "            raise ValueError(f\"Failed to extract prompts using regex: {e}\")\n",
        "\n",
        "    if not isinstance(prompt_list, list):\n",
        "        raise ValueError(\"Parsed output is not a list.\")\n",
        "\n",
        "except Exception as e:\n",
        "    raise ValueError(f\"Failed to parse prompts from agent: {e}\")\n",
        "\n",
        "\n",
        "print(f\"âœ… Got {len(prompt_list)} prompts from agent!\")\n",
        "\n",
        "# === ðŸŽ¨ STEP 3: Generate and save images ===\n",
        "client = openai.OpenAI(\n",
        "    api_key= userdata.get(\"OPENAI_API_KEY\")\n",
        ")\n",
        "for idx, prompt in enumerate(prompt_list):\n",
        "    try:\n",
        "        print(f\"[{idx+1}/{len(prompt_list)}] Generating image for prompt: {prompt}\")\n",
        "\n",
        "        response = client.images.generate(\n",
        "            model=\"dall-e-2\",  # or \"dall-e-2\"\n",
        "            prompt=prompt,\n",
        "            size=\"256x256\",\n",
        "            quality=\"standard\",\n",
        "            n=1\n",
        "        )\n",
        "\n",
        "        image_url = response[\"data\"][0][\"url\"]\n",
        "        image_data = requests.get(image_url).content\n",
        "        file_path = os.path.join(output_dir, f\"image_{idx+1:02}.png\")\n",
        "\n",
        "        with open(file_path, 'wb') as f:\n",
        "            f.write(image_data)\n",
        "\n",
        "        print(f\"âœ… Saved: {file_path}\")\n",
        "        sleep(1)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error with prompt {idx+1}: {e}\")\n"
      ],
      "metadata": {
        "id": "pVNemTlLV28W",
        "outputId": "da0201da-c270-473e-8039-6af3bf6e9cb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a scenario (or type 'exit' to quit): trees\n",
            "```python\n",
            "[\"A towering redwood sequoia bathed in dappled sunlight, towering over a lush forest floor.\", \n",
            "\"A lone, gnarled oak tree standing sentinel on a windswept hilltop, branches reaching towards the stormy sky.\",\n",
            "\"A grove of ancient olive trees, their silvery leaves shimmering in the Mediterranean sun.\",\n",
            "\"A vibrant Japanese maple, ablaze with autumn colors, leaves cascading down like fiery rain.\",\n",
            "\"Twisted and ancient cypress trees lining a foggy Italian path, creating an eerie and mysterious atmosphere.\",\n",
            "\"A young sapling, its delicate leaves unfurling in the spring breeze, surrounded by wildflowers.\",\n",
            "\"A dense forest of towering pine trees, their needles carpeting the ground in a thick layer of green.\",\n",
            "\"A panoramic view of a sprawling forest, sunlight filtering through the leaves, creating a mosaic of light and shadow.\",\n",
            "\"A close-up shot of a tree bark, showcasing its intricate patterns and textures.\",\n",
            "\"A cluster of birch trees, their white bark glowing in the moonlight, casting long shadows on the forest floor.\",\n",
            "\"A deciduous forest in full bloom, flowers carpeting the ground beneath the canopy of leaves.\",\n",
            "\"An abstract representation of a tree, using lines and shapes to capture its essence.\",\n",
            "\"A tree silhouette against a fiery sunset, casting a long, dramatic shadow.\",\n",
            "\"A surreal image of a tree growing through a cityscape, its roots reaching towards the sky.\",\n",
            "\"A whimsical illustration of a treehouse nestled amongst the branches of a giant oak.\",\n",
            "\"A magical forest scene, with glowing mushrooms and bioluminescent trees.\",\n",
            "\"A winter wonderland, with snow-covered trees and frozen lakes.\",\n",
            "\"A dense jungle, with towering trees and exotic flowers.\",\n",
            "\"A desert oasis, with a lone palm tree providing shade and water.\",\n",
            "\"A futuristic cityscape, with towering trees incorporated into the architecture.\",\n",
            "\"A tree with glowing, bioluminescent leaves, illuminating the forest at night.\",\n",
            "\"A tree growing out of a cracked earth, symbolizing resilience and hope.\",\n",
            "\"A tree with roots reaching deep into the ocean, connecting to the depths of the earth.\",\n",
            "\"A tree with fruit that resembles human faces, creating a sense of surrealism.\",\n",
            "\"A tree with branches that transform into birds in flight.\",\n",
            "\"A tree with leaves that change color with the viewer's emotions.\",\n",
            "\"A tree with its branches forming the shape of a human figure.\",\n",
            "\"A tree with its roots forming a labyrinthine maze.\",\n",
            "\"A tree with its trunk covered in ancient hieroglyphics.\",\n",
            "\"A tree with its leaves forming a protective canopy over a village below.\",\n",
            "\"A tree with its branches stretching towards the stars, symbolizing aspirations and dreams.\",\n",
            "\"A tree sculpted from ice, shimmering in the sunlight.\",\n",
            "\"A tree made entirely of flowers, blooming in all colors.\",\n",
            "\"A tree with its roots forming a giant heart, symbolizing love and connection.\",\n",
            "\"A tree with its leaves whispering secrets to the wind.\",\n",
            "\"A tree with its branches reaching out to embrace the world.\",\n",
            "\"A tree with its trunk glowing with an ethereal light.\",\n",
            "\"A tree that transcends the boundaries of reality, existing in multiple dimensions.\",\n",
            "\"A tree that represents the cycle of life, death, and rebirth.\"] \n",
            "``` \n",
            "\n",
            "\n",
            "\n",
            "âœ… Got 39 prompts from agent!\n",
            "[1/39] Generating image for prompt: A towering redwood sequoia bathed in dappled sunlight, towering over a lush forest floor.\n",
            "âŒ Error with prompt 1: Error code: 400 - {'error': {'code': 'billing_hard_limit_reached', 'message': 'Billing hard limit has been reached', 'param': None, 'type': 'invalid_request_error'}}\n",
            "[2/39] Generating image for prompt: A lone, gnarled oak tree standing sentinel on a windswept hilltop, branches reaching towards the stormy sky.\n",
            "âŒ Error with prompt 2: Error code: 400 - {'error': {'code': 'billing_hard_limit_reached', 'message': 'Billing hard limit has been reached', 'param': None, 'type': 'invalid_request_error'}}\n",
            "[3/39] Generating image for prompt: A grove of ancient olive trees, their silvery leaves shimmering in the Mediterranean sun.\n",
            "âŒ Error with prompt 3: Error code: 400 - {'error': {'code': 'billing_hard_limit_reached', 'message': 'Billing hard limit has been reached', 'param': None, 'type': 'invalid_request_error'}}\n",
            "[4/39] Generating image for prompt: A vibrant Japanese maple, ablaze with autumn colors, leaves cascading down like fiery rain.\n",
            "âŒ Error with prompt 4: Error code: 400 - {'error': {'code': 'billing_hard_limit_reached', 'message': 'Billing hard limit has been reached', 'param': None, 'type': 'invalid_request_error'}}\n",
            "[5/39] Generating image for prompt: Twisted and ancient cypress trees lining a foggy Italian path, creating an eerie and mysterious atmosphere.\n",
            "âŒ Error with prompt 5: Error code: 400 - {'error': {'code': 'billing_hard_limit_reached', 'message': 'Billing hard limit has been reached', 'param': None, 'type': 'invalid_request_error'}}\n",
            "[6/39] Generating image for prompt: A young sapling, its delicate leaves unfurling in the spring breeze, surrounded by wildflowers.\n",
            "âŒ Error with prompt 6: Error code: 429 - {'error': {'code': 'rate_limit_exceeded', 'message': 'Rate limit exceeded for images per minute in organization org-t80GchCytxtJrChnmmxg6lXm. Limit: 5/1min. Current: 6/1min. Please visit https://platform.openai.com/docs/guides/rate-limits to learn how to increase your rate limit.', 'param': None, 'type': 'requests'}}\n",
            "[7/39] Generating image for prompt: A dense forest of towering pine trees, their needles carpeting the ground in a thick layer of green.\n",
            "âŒ Error with prompt 7: Error code: 429 - {'error': {'code': 'rate_limit_exceeded', 'message': 'Rate limit exceeded for images per minute in organization org-t80GchCytxtJrChnmmxg6lXm. Limit: 5/1min. Current: 6/1min. Please visit https://platform.openai.com/docs/guides/rate-limits to learn how to increase your rate limit.', 'param': None, 'type': 'requests'}}\n",
            "[8/39] Generating image for prompt: A panoramic view of a sprawling forest, sunlight filtering through the leaves, creating a mosaic of light and shadow.\n",
            "âŒ Error with prompt 8: Error code: 429 - {'error': {'code': 'rate_limit_exceeded', 'message': 'Rate limit exceeded for images per minute in organization org-t80GchCytxtJrChnmmxg6lXm. Limit: 5/1min. Current: 6/1min. Please visit https://platform.openai.com/docs/guides/rate-limits to learn how to increase your rate limit.', 'param': None, 'type': 'requests'}}\n",
            "[9/39] Generating image for prompt: A close-up shot of a tree bark, showcasing its intricate patterns and textures.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPStatusError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m             \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1003\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPStatusError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# thrown on 4xx and 5xx status code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPStatusError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPStatusError\u001b[0m: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/images/generations'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mHTTPStatusError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m             \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1003\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPStatusError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# thrown on 4xx and 5xx status code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPStatusError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPStatusError\u001b[0m: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/images/generations'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-d40bdfa72595>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[{idx+1}/{len(prompt_list)}] Generating image for prompt: {prompt}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         response = client.images.generate(\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"dall-e-2\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# or \"dall-e-2\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/resources/images.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, prompt, model, n, quality, response_format, size, style, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    262\u001b[0m           \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOverride\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlevel\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseconds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \"\"\"\n\u001b[0;32m--> 264\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    265\u001b[0m             \u001b[0;34m\"/images/generations\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1240\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m         )\n\u001b[0;32m-> 1242\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0mretries_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 919\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    920\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1006\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mremaining_retries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1008\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m   1009\u001b[0m                     \u001b[0minput_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1057\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m   1058\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1006\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mremaining_retries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1008\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m   1009\u001b[0m                     \u001b[0minput_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0;31m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m         \u001b[0;31m# different thread if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1055\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1056\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m         return self._request(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NcZdo9WeV2-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IoS_BAAJV3B5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}